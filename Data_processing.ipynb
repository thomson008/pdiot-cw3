{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Data processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomson008/pdiot-cw3/blob/main/Data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHPI5pTirx3A",
        "outputId": "3e1b14d9-6f5e-446a-d45b-13035490496c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "from keras import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJmZ1updrx3D"
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/pdiot-cw3/data'\n",
        "\n",
        "file_list = []\n",
        "sensor_position = 'Chest_Right'\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        if ('csv' in file and sensor_position in file):\n",
        "            file_list.append(os.path.join(root, file))\n",
        "            \n",
        "dataframes = []\n",
        "\n",
        "for file in file_list:\n",
        "    with open(file) as f:\n",
        "        info = [next(f).rstrip().split(': ')[1] for x in range(5)]\n",
        "        user_id = info[4]\n",
        "        activity = info[2]\n",
        "        \n",
        "    file_data = pd.read_csv(file, header=5)\n",
        "    if (file_data.size):\n",
        "        dataframes.append(file_data)\n",
        "        file_data.insert(0, 'user_id', user_id)\n",
        "        file_data.insert(1, 'activity', activity)\n",
        "    \n",
        "\n",
        "sensor_data = pd.concat(dataframes, ignore_index=True).drop('seq', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOKgSyE1rx3F"
      },
      "source": [
        "scale_columns = ['accel_x', 'accel_y', 'accel_z']\n",
        "\n",
        "def split_data(leave_subject):\n",
        "    subjects = sensor_data.user_id.unique()\n",
        "    train_subjects, test_subjects = subjects[: int(0.98*len(subjects))], subjects[int(0.98*len(subjects)):]\n",
        "\n",
        "    df_train, df_test = sensor_data[sensor_data.user_id != leave_subject], sensor_data[sensor_data.user_id == leave_subject]\n",
        "\n",
        "    scaler = RobustScaler()\n",
        "\n",
        "    scaler = scaler.fit(df_train[scale_columns])\n",
        "\n",
        "    df_train.loc[:, scale_columns] = scaler.transform(\n",
        "      df_train.loc[:, scale_columns].to_numpy()\n",
        "    )\n",
        "\n",
        "    df_test.loc[:, scale_columns] = scaler.transform(\n",
        "      df_test.loc[:, scale_columns].to_numpy()\n",
        "    )\n",
        "\n",
        "    return df_train, df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH81IgNCrx3I",
        "outputId": "8fca915f-e72b-49c2-ba26-b2d4e9a8e8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def create_dataset(X, y, time_steps=1, step=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(0, len(X) - time_steps, step):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        labels = y.iloc[i: i + time_steps]\n",
        "        Xs.append(v)\n",
        "        ys.append(stats.mode(labels)[0][0])\n",
        "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
        "\n",
        "TIME_STEPS = 36\n",
        "STEP = 10\n",
        "\n",
        "def create_whole_dataset(time_steps, step):\n",
        "    df_train, df_test = split_data('s1758009')\n",
        "    X_train, y_train = create_dataset(\n",
        "        df_train[scale_columns],\n",
        "        df_train.activity,\n",
        "        time_steps,\n",
        "        step\n",
        "    )\n",
        "\n",
        "    X_test, y_test = create_dataset(\n",
        "        df_test[scale_columns],\n",
        "        df_test.activity,\n",
        "        time_steps,\n",
        "        step\n",
        "    )\n",
        "\n",
        "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "\n",
        "    enc = enc.fit(y_train)\n",
        "\n",
        "    y_train = enc.transform(y_train)\n",
        "    y_test = enc.transform(y_test)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = create_whole_dataset(TIME_STEPS, STEP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_1ki4bR8j7R",
        "outputId": "c4ba7eba-e5b6-4cfa-e8f2-33b3a18b345a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "def create_model(trainX, trainy, testX, testy):\n",
        "\tverbose, epochs, batch_size = 1, 10, 32\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(MaxPooling1D(pool_size=2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model\n",
        "\n",
        "model = create_model(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# evaluate model\n",
        "_, accuracy = model.evaluate(X_test, y_test, batch_size=32, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 1.2428 - accuracy: 0.5717\n",
            "Epoch 2/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.7507 - accuracy: 0.7284\n",
            "Epoch 3/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.6210 - accuracy: 0.7723\n",
            "Epoch 4/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.5081 - accuracy: 0.8250\n",
            "Epoch 5/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.4483 - accuracy: 0.8409\n",
            "Epoch 6/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.3992 - accuracy: 0.8563\n",
            "Epoch 7/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.3707 - accuracy: 0.8653\n",
            "Epoch 8/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.3392 - accuracy: 0.8782\n",
            "Epoch 9/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.3118 - accuracy: 0.8857\n",
            "Epoch 10/10\n",
            "212/212 [==============================] - 2s 8ms/step - loss: 0.3095 - accuracy: 0.8891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-xVSziIYRsz",
        "outputId": "2e48fbd7-1cf6-4b5c-8ccb-223eeaffaf33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp_cf5987n/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DScAzOkGyJTO",
        "outputId": "ed8d4bc1-7d25-48aa-d7a1-1d5ea362af0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_7 (Conv1D)            (None, 34, 64)            640       \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 32, 64)            12352     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 16, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               102500    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 15)                1515      \n",
            "=================================================================\n",
            "Total params: 117,007\n",
            "Trainable params: 117,007\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjVxhQ09xnn9",
        "outputId": "c57fb8f8-9c36-4719-d1e4-5fbb8fdc424a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.input_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 36, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcV2fZchySxD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}